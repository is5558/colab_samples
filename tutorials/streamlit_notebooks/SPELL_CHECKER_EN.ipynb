{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/is5558/colab_samples/blob/main/tutorials/streamlit_notebooks/SPELL_CHECKER_EN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4b_2KemgDWf"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/SPELL_CHECKER_EN.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnZG0I4ogNLI"
      },
      "source": [
        "# **Spell check your text documents**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apjCmRyjgQll"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2phEj9SygX4n"
      },
      "source": [
        "Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAiXj3DOfyZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9d3302e-1139-4060-e48f-fd86cd5e4767"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/718.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/718.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m716.8/718.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.8/718.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install PySpark and Spark NLP\n",
        "! pip install -q pyspark spark-nlp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "\n",
        "def initialize_spark_nlp():\n",
        "    try:\n",
        "        spark = sparknlp.start()\n",
        "        print(\"Spark NLP version:\", sparknlp.version())\n",
        "        return spark\n",
        "    except Exception as e:\n",
        "        print(\"Error initializing Spark NLP session:\", str(e))\n",
        "        raise\n",
        "\n",
        "def load_pipeline(pipeline_name='check_spelling', lang='en'):\n",
        "\n",
        "    try:\n",
        "        return PretrainedPipeline(pipeline_name, lang=lang)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading pipeline '{pipeline_name}':\", str(e))\n",
        "        raise\n",
        "\n",
        "def get_corrected_text(annotations):\n",
        "    try:\n",
        "        corrected_tokens = [token.result for token in annotations['checked']]\n",
        "        return \" \".join(corrected_tokens).replace(\" ,\", \",\").replace(\" .\", \".\")\n",
        "    except KeyError:\n",
        "        print(\"Error: 'checked' key not found in annotations.\")\n",
        "        return \"\"\n",
        "\n",
        "def main():\n",
        "    text = (\n",
        "        \"Yesturday, I went to the libary to borow a book about anciant civilizations. \"\n",
        "        \"The wether was pleasent, so I decidid to walk insted of taking the buss. On the way, \"\n",
        "        \"I saw a restuarent that lookt intresting, and I plan to viset it soon.\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        # Initialize Spark NLP and load the pipeline\n",
        "        spark = initialize_spark_nlp()\n",
        "        pipeline = load_pipeline()\n",
        "\n",
        "        # Annotate text\n",
        "        annotations = pipeline.fullAnnotate(text)[0]\n",
        "\n",
        "        # Get and print corrected text\n",
        "        corrected_text = get_corrected_text(annotations)\n",
        "        print(\"*\"*77)\n",
        "        print(\"Original Text:\\n\", text)\n",
        "        print(\"Corrected Text:\\n\", corrected_text)\n",
        "        print(\"*\"*77)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"An unexpected error occurred:\", str(e))\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DJnasw_YhUo",
        "outputId": "05933539-c87c-4f6b-db55-55285b21a074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning::Spark Session already created, some configs may not take.\n",
            "Spark NLP version: 6.0.4\n",
            "check_spelling download started this may take some time.\n",
            "Approx size to download 884.9 KB\n",
            "[OK!]\n",
            "*****************************************************************************\n",
            "Original Text:\n",
            " Yesturday, I went to the libary to borow a book about anciant civilizations. The wether was pleasent, so I decidid to walk insted of taking the buss. On the way, I saw a restuarent that lookt intresting, and I plan to viset it soon.\n",
            "Corrected Text:\n",
            " Yesterday, I went to the library to borrow a book about ancient civilizations. The whether was pleasant, so I decided to walk instead of taking the bus. On the way, I saw a restuarent that looks interesting, and I plan to visit it soon.\n",
            "*****************************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building Docker Image**"
      ],
      "metadata": {
        "id": "VpZPb2wHxiPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! zip -r spell_check_project.zip /content/spell-check-project/\n"
      ],
      "metadata": {
        "id": "TYGzGpg1xKH_",
        "outputId": "f48bbeaf-fdf5-4131-b747-e8d33682042e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/spell-check-project/ (stored 0%)\n",
            "  adding: content/spell-check-project/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/spell-check-project/spell_check.py (deflated 55%)\n",
            "  adding: content/spell-check-project/Dockerfile (deflated 53%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Docker in Colab\n",
        "!curl -fsSL https://get.docker.com -o get-docker.sh\n",
        "!sh get-docker.sh\n",
        "\n",
        "# Restart the docker service\n",
        "!service docker start\n",
        "\n",
        "# Unzip uploaded project\n",
        "!unzip -o /content/spell_check_project.zip\n",
        "\n",
        "# Build Docker image\n",
        "!docker build -t spell-check-image spell_check_project/\n",
        "\n",
        "# Run the Docker container\n",
        "!docker run --rm spell-check-image\n"
      ],
      "metadata": {
        "id": "zcqao7bSxoKA",
        "outputId": "a9389567-a064-477a-b118-21bb77bc4ed7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Executing docker install script, commit: 7040dd2bf115a359317b1de84de611aeabcb7bc2\n",
            "+ sh -c apt-get -qq update >/dev/null\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "+ sh -c DEBIAN_FRONTEND=noninteractive apt-get -y -qq install ca-certificates curl >/dev/null\n",
            "+ sh -c install -m 0755 -d /etc/apt/keyrings\n",
            "+ sh -c curl -fsSL \"https://download.docker.com/linux/ubuntu/gpg\" -o /etc/apt/keyrings/docker.asc\n",
            "+ sh -c chmod a+r /etc/apt/keyrings/docker.asc\n",
            "+ sh -c echo \"deb [arch=amd64 signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu jammy stable\" > /etc/apt/sources.list.d/docker.list\n",
            "+ sh -c apt-get -qq update >/dev/null\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "+ sh -c DEBIAN_FRONTEND=noninteractive apt-get -y -qq install docker-ce docker-ce-cli containerd.io docker-compose-plugin docker-ce-rootless-extras docker-buildx-plugin docker-model-plugin >/dev/null\n",
            "\n",
            "================================================================================\n",
            "\n",
            "To run Docker as a non-privileged user, consider setting up the\n",
            "Docker daemon in rootless mode for your user:\n",
            "\n",
            "    dockerd-rootless-setuptool.sh install\n",
            "\n",
            "Visit https://docs.docker.com/go/rootless/ to learn about rootless mode.\n",
            "\n",
            "\n",
            "To run the Docker daemon as a fully privileged service, but granting non-root\n",
            "users access, refer to https://docs.docker.com/go/daemon-access/\n",
            "\n",
            "WARNING: Access to the remote API on a privileged Docker daemon is equivalent\n",
            "         to root access on the host. Refer to the 'Docker daemon attack surface'\n",
            "         documentation for details: https://docs.docker.com/go/attack-surface/\n",
            "\n",
            "================================================================================\n",
            "\n",
            "/etc/init.d/docker: 62: ulimit: error setting limit (Invalid argument)\n",
            "Archive:  /content/spell_check_project.zip\n",
            "   creating: content/spell-check-project/\n",
            "   creating: content/spell-check-project/.ipynb_checkpoints/\n",
            "  inflating: content/spell-check-project/spell_check.py  \n",
            "  inflating: content/spell-check-project/Dockerfile  \n",
            "ERROR: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\n",
            "docker: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\n",
            "\n",
            "Run 'docker run --help' for more information\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "45150093197569bb3a58481dcd32cd1adb45462fa3448719e8ac38ada6166aca"
    },
    "kernelspec": {
      "display_name": "Python 3.6.10 64-bit ('tensorflow2_p36': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}